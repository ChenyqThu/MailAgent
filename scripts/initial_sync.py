#!/usr/bin/env python3
"""
åˆå§‹åŒ–åŒæ­¥è„šæœ¬

æ–°æ¶æ„çš„åˆå§‹åŒ–æµç¨‹ï¼š
1. AppleScript è·å–é‚®ä»¶ï¼ˆæ”¶ä»¶ç®± + å‘ä»¶ç®±ï¼‰
2. å†™å…¥ SyncStore (email_metadata è¡¨)
3. ä» Notion æ‹‰å–å·²åŒæ­¥é‚®ä»¶çš„ message_id
4. æ¯”å¯¹æ ¡éªŒï¼Œæ ‡è®°å·²åŒæ­¥çš„é‚®ä»¶
5. æç¤ºç”¨æˆ·ç¡®è®¤åï¼ŒåŒæ­¥æ‰€æœ‰ pending é‚®ä»¶

Usage:
    # å®Œæ•´æµç¨‹ï¼ˆåˆ†æ + åŒæ­¥ï¼‰
    python scripts/initial_sync.py

    # è·³è¿‡ç¡®è®¤æ­¥éª¤
    python scripts/initial_sync.py --yes

    # åªåŒæ­¥æŒ‡å®šæ•°é‡
    python scripts/initial_sync.py --limit 100

    # === åˆ†ç¦»å¼æ‰§è¡Œ ===

    # Phase 1: ä»…åˆ†æï¼Œç”ŸæˆæŠ¥å‘Š
    python scripts/initial_sync.py --action analyze --output data/analysis.json

    # Phase 2: åŸºäºæŠ¥å‘Šæ‰§è¡Œæ“ä½œ
    python scripts/initial_sync.py --action fix-properties --input data/analysis.json
    python scripts/initial_sync.py --action sync-new --input data/analysis.json --limit 100

    # å¯ç”¨çš„ action:
    #   analyze              ä»…åˆ†æ SyncStore vs Notion + Parent Item çŠ¶æ€
    #   fix-properties       ä¿®å¤ date/thread_id ä¸åŒ
    #   fix-critical         é‡æ–°åŒæ­¥å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶ï¼ˆåˆ é™¤æ—§é¡µé¢ï¼‰
    #   fix-parent           ä¿®å¤ç¼ºå¤± Parent Itemï¼ˆåŸºäº analyze æŠ¥å‘Šï¼‰
    #   update-all-parents   éå†éªŒè¯å¹¶ä¿®å¤æ‰€æœ‰ Parent Itemï¼ˆç‹¬ç«‹åˆ†æï¼Œæ¨èï¼‰
    #   sync-thread-heads    åŒæ­¥ç¼ºå¤±çš„çº¿ç¨‹å¤´
    #   sync-new             åŒæ­¥æ–°é‚®ä»¶
    #   all                  æ‰§è¡Œæ‰€æœ‰ä¿®å¤å’ŒåŒæ­¥

å¼‚å¸¸åˆ†ç±»è¯´æ˜:
    - matched: å®Œå…¨åŒ¹é…ï¼ˆè‡ªåŠ¨æ ‡è®°ä¸ºå·²åŒæ­¥ï¼‰
    - property_mismatch: date æˆ– thread_id ä¸åŒ â†’ fix-properties æ›´æ–°å±æ€§
    - critical_mismatch: subject æˆ– sender ä¸åŒ â†’ fix-critical åˆ é™¤é‡å»º
    - store_only: ä»…åœ¨ SyncStore â†’ sync-new åŒæ­¥åˆ° Notion
    - notion_only: ä»…åœ¨ Notionï¼ˆå¯èƒ½å·²å¬å›ï¼‰â†’ ä¸å¤„ç†
    - missing_parent: ç¼ºå¤± Parent Item â†’ fix-parent å…³è”
    - orphan_threads_*: çº¿ç¨‹å¤´ç¼ºå¤± â†’ sync-thread-heads åŒæ­¥
    - unfixable_thread_heads: æ— æ³•ä¿®å¤çš„çº¿ç¨‹å¤´ï¼ˆæœ€åè¾“å‡ºç»Ÿè®¡ï¼‰
"""

import asyncio
import argparse
import json
import sys
import time
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŒ—äº¬æ—¶åŒº
BEIJING_TZ = timezone(timedelta(hours=8))

from loguru import logger
from src.config import config as settings
from src.models import Email
from src.mail.sqlite_radar import SQLiteRadar
from src.mail.applescript_arm import AppleScriptArm
from src.mail.sync_store import SyncStore
from src.mail.reader import EmailReader
from src.notion.sync import NotionSync


def get_system_timezone() -> timezone:
    """è·å–ç³»ç»Ÿå½“å‰æ—¶åŒºï¼ˆè€ƒè™‘å¤ä»¤æ—¶ï¼‰"""
    local_time = time.localtime()
    if local_time.tm_isdst > 0:
        offset_seconds = -time.altzone
    else:
        offset_seconds = -time.timezone
    return timezone(timedelta(seconds=offset_seconds))


def parse_chinese_datetime(date_str: str) -> Optional[datetime]:
    """è§£æä¸­æ–‡æ—¥æœŸæ ¼å¼

    æ”¯æŒæ ¼å¼ï¼š
    - "2025å¹´9æœˆ9æ—¥ æ˜ŸæœŸäºŒ ä¸‹åˆ8:48:14"
    - "2025å¹´1æœˆ13æ—¥ æ˜ŸæœŸä¸€ ä¸Šåˆ10:30:00"

    Returns:
        datetime å¯¹è±¡ï¼ˆæ— æ—¶åŒºï¼‰ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    import re

    # åŒ¹é…ä¸­æ–‡æ—¥æœŸæ ¼å¼
    pattern = r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥\s+æ˜ŸæœŸ[ä¸€äºŒä¸‰å››äº”å…­æ—¥]\s+(ä¸Šåˆ|ä¸‹åˆ)(\d{1,2}):(\d{2}):(\d{2})'
    match = re.match(pattern, date_str)
    if not match:
        return None

    year = int(match.group(1))
    month = int(match.group(2))
    day = int(match.group(3))
    am_pm = match.group(4)
    hour = int(match.group(5))
    minute = int(match.group(6))
    second = int(match.group(7))

    # è½¬æ¢ 12 å°æ—¶åˆ¶ä¸º 24 å°æ—¶åˆ¶
    if am_pm == "ä¸‹åˆ" and hour < 12:
        hour += 12
    elif am_pm == "ä¸Šåˆ" and hour == 12:
        hour = 0

    return datetime(year, month, day, hour, minute, second)


def parse_datetime_with_tz(date_str: str, default_tz: timezone = None) -> Optional[datetime]:
    """è§£ææ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ”¯æŒå¸¦æ—¶åŒºå’Œä¸å¸¦æ—¶åŒºçš„æ ¼å¼

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ "2026-01-24T14:02:32" æˆ– "2026-01-24T14:02:32+08:00"
                  ä¹Ÿæ”¯æŒä¸­æ–‡æ ¼å¼å¦‚ "2025å¹´9æœˆ9æ—¥ æ˜ŸæœŸäºŒ ä¸‹åˆ8:48:14"
        default_tz: æ— æ—¶åŒºæ—¶ä½¿ç”¨çš„é»˜è®¤æ—¶åŒºï¼ˆNone æ—¶ä½¿ç”¨ç³»ç»Ÿæ—¶åŒºï¼‰

    Returns:
        å¸¦æ—¶åŒºçš„ datetime å¯¹è±¡ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    if not date_str:
        return None

    # å…ˆå°è¯•è§£æä¸­æ–‡æ—¥æœŸæ ¼å¼
    if "å¹´" in date_str and "æœˆ" in date_str:
        dt = parse_chinese_datetime(date_str)
        if dt:
            if default_tz is None:
                default_tz = get_system_timezone()
            return dt.replace(tzinfo=default_tz)
        return None

    try:
        # å°è¯•è§£æ ISO æ ¼å¼ï¼ˆå¯èƒ½å¸¦æ—¶åŒºï¼‰
        if "+" in date_str or date_str.endswith("Z") or (date_str.count("-") > 2 and "T" in date_str):
            # å¤„ç† Notion è¿”å›çš„æ¯«ç§’æ ¼å¼: 2026-01-24T22:02:00.000+08:00
            date_str_clean = date_str.replace("Z", "+00:00")
            return datetime.fromisoformat(date_str_clean)
        else:
            # æ— æ—¶åŒºï¼Œæ·»åŠ é»˜è®¤æ—¶åŒº
            dt = datetime.fromisoformat(date_str)
            if default_tz is None:
                default_tz = get_system_timezone()
            return dt.replace(tzinfo=default_tz)
    except Exception as e:
        logger.debug(f"Failed to parse datetime '{date_str}': {e}")
        return None


def dates_match(store_date_str: str, notion_date_str: str, tolerance_seconds: int = 120) -> bool:
    """æ¯”è¾ƒä¸¤ä¸ªæ—¥æœŸæ˜¯å¦åŒ¹é…ï¼ˆè½¬æ¢ä¸º UTC æ¯”è¾ƒï¼Œå…è®¸ä¸€å®šå®¹å·®ï¼‰

    Args:
        store_date_str: SyncStore ä¸­çš„æ—¥æœŸå­—ç¬¦ä¸²
        notion_date_str: Notion ä¸­çš„æ—¥æœŸå­—ç¬¦ä¸²
        tolerance_seconds: å…è®¸çš„è¯¯å·®ç§’æ•°ï¼ˆé»˜è®¤ 120 ç§’ï¼‰

    Returns:
        æ˜¯å¦åŒ¹é…
    """
    store_dt = parse_datetime_with_tz(store_date_str)
    notion_dt = parse_datetime_with_tz(notion_date_str)

    if store_dt is None or notion_dt is None:
        # æ— æ³•è§£æï¼Œå›é€€åˆ°æ—¥æœŸå­—ç¬¦ä¸²æ¯”è¾ƒ
        store_date = (store_date_str or '')[:10]
        notion_date = (notion_date_str or '')[:10]
        return store_date == notion_date

    # è½¬æ¢ä¸º UTC æ¯”è¾ƒ
    store_utc = store_dt.astimezone(timezone.utc)
    notion_utc = notion_dt.astimezone(timezone.utc)

    diff_seconds = abs((store_utc - notion_utc).total_seconds())
    return diff_seconds <= tolerance_seconds


def is_notion_date_beijing_tz(notion_date_str: str) -> bool:
    """æ£€æŸ¥ Notion æ—¥æœŸæ˜¯å¦æ˜¯åŒ—äº¬æ—¶åŒº"""
    if not notion_date_str:
        return False
    return "+08:00" in notion_date_str


class AnalysisReport:
    """åˆ†ææŠ¥å‘Šç±»ï¼Œæ”¯æŒ JSON åºåˆ—åŒ–"""

    def __init__(self):
        self.created_at: str = datetime.now().isoformat()
        self.comparison: Dict = {
            'matched': [],
            'property_mismatch': [],      # date æˆ– thread_id ä¸åŒï¼ˆåˆå¹¶ï¼‰
            'critical_mismatch': [],      # subject æˆ– sender ä¸åŒ
            'store_only': [],             # å¾…åŒæ­¥ï¼ˆå·²è¿‡æ»¤æ—¥æœŸï¼‰
            'store_only_before_date': [], # æ—©äº sync_start_dateï¼ˆä»…ç¼“å­˜ï¼ŒæŒ‰éœ€åŒæ­¥ï¼‰
            'notion_only': [],            # ä»…åœ¨ Notionï¼ˆä¸å¤„ç†ï¼Œå¯èƒ½æ˜¯å¬å›é‚®ä»¶ï¼‰
        }
        self.parent_analysis: Dict = {
            'total': 0,
            'thread_heads': {
                'correct': [],      # çº¿ç¨‹å¤´ï¼ŒParent å·²æ­£ç¡®ï¼ˆç©ºï¼‰
                'need_clear': [],   # çº¿ç¨‹å¤´ï¼Œä½†æœ‰ Parentï¼ˆéœ€æ¸…ç©ºï¼‰
            },
            'replies': {
                'correct': [],              # å›å¤ï¼ŒParent å·²æ­£ç¡®
                'need_update_notion': [],   # å›å¤ï¼Œçº¿ç¨‹å¤´åœ¨ Notionï¼Œéœ€æ›´æ–°
                'need_sync_store': [],      # å›å¤ï¼Œçº¿ç¨‹å¤´åœ¨ SyncStore æœªåŒæ­¥
                'need_fallback': [],        # å›å¤ï¼Œéœ€ä½¿ç”¨é™çº§æ–¹æ¡ˆ
                'no_parent_available': [],  # å›å¤ï¼Œæ‰¾ä¸åˆ°åˆé€‚ Parentï¼ˆå­¤å„¿å›å¤ï¼‰
            }
        }
        self.stats: Dict = {
            "fetched_from_applescript": 0,
            "saved_to_store": 0,
            "already_in_notion": 0,
            "pending_sync": 0,
            "synced": 0,
            "failed": 0
        }

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "created_at": self.created_at,
            "comparison": self.comparison,
            "parent_analysis": self.parent_analysis,
            "stats": self.stats
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'AnalysisReport':
        """ä»å­—å…¸åˆ›å»º"""
        report = cls()
        report.created_at = data.get("created_at", "")
        report.comparison = data.get("comparison", report.comparison)
        report.parent_analysis = data.get("parent_analysis", report.parent_analysis)
        report.stats = data.get("stats", report.stats)
        return report

    def save(self, path: str):
        """ä¿å­˜åˆ° JSON æ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
        print(f"  âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {path}")

    @classmethod
    def load(cls, path: str) -> 'AnalysisReport':
        """ä» JSON æ–‡ä»¶åŠ è½½"""
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        report = cls.from_dict(data)
        print(f"  âœ… å·²åŠ è½½æŠ¥å‘Š: {path} (åˆ›å»ºäº {report.created_at})")
        return report


class InitialSync:
    """åˆå§‹åŒ–åŒæ­¥å™¨"""

    def __init__(self, sync_store_path: str = "data/sync_store.db", mailbox_limits: Dict[str, int] = None):
        """åˆå§‹åŒ–

        Args:
            sync_store_path: SyncStore æ•°æ®åº“è·¯å¾„
            mailbox_limits: æ¯ä¸ªé‚®ç®±çš„è·å–æ•°é‡é™åˆ¶ï¼Œå¦‚ {"æ”¶ä»¶ç®±": 3000, "å‘ä»¶ç®±": 500}
                           None æˆ– 0 è¡¨ç¤ºä¸é™åˆ¶
        """
        # ä»é…ç½®è¯»å–é‚®ç®±åˆ—è¡¨ï¼Œæ”¯æŒè‡ªå®šä¹‰
        self.mailboxes = getattr(settings, 'init_mailboxes', ["æ”¶ä»¶ç®±", "å‘ä»¶ç®±"])
        self.mailbox_limits = mailbox_limits or {}

        # åˆå§‹åŒ–ç»„ä»¶
        self.radar = SQLiteRadar(mailboxes=self.mailboxes)
        self.arm = AppleScriptArm(
            account_name=settings.mail_account_name,
            inbox_name=settings.mail_inbox_name
        )
        self.sync_store = SyncStore(sync_store_path)
        self.notion_sync = NotionSync()
        self.email_reader = EmailReader()

        # åˆ†ææŠ¥å‘Š
        self.report = AnalysisReport()

    @property
    def comparison(self) -> Dict:
        """å…¼å®¹æ—§ä»£ç çš„å±æ€§"""
        return self.report.comparison

    @property
    def stats(self) -> Dict:
        """å…¼å®¹æ—§ä»£ç çš„å±æ€§"""
        return self.report.stats

    # ==================== ä¸»æµç¨‹ ====================

    async def run(self, auto_confirm: bool = False, limit: int = None):
        """è¿è¡Œåˆå§‹åŒ–åŒæ­¥ï¼ˆå®Œæ•´æµç¨‹ï¼‰

        Args:
            auto_confirm: æ˜¯å¦è·³è¿‡ç¡®è®¤æ­¥éª¤
            limit: é™åˆ¶åŒæ­¥æ•°é‡
        """
        print("\n" + "=" * 60)
        print("MailAgent åˆå§‹åŒ–åŒæ­¥")
        print("=" * 60)

        # Step 1: æ£€æŸ¥ç¯å¢ƒ
        print("\n Step 1: æ£€æŸ¥ç¯å¢ƒ...")
        if not self._check_environment():
            return

        # Step 1.5: è®°å½•å½“å‰ max_row_idï¼ˆç”¨äºåç»­å¢é‡åŒæ­¥ï¼‰
        print("\n è®°å½•å½“å‰ max_row_id...")
        self._record_current_max_row_id()

        # Step 2: ä» AppleScript è·å–é‚®ä»¶ï¼ˆå¢é‡æ¨¡å¼ï¼‰
        print("\n Step 2: ä» Mail.app è·å–é‚®ä»¶...")
        if not await self._fetch_emails_from_applescript():
            return

        # Step 3: åˆ†æ SyncStore vs Notion
        print("\n Step 3: åˆ†ææ•°æ®...")
        try:
            await self._analyze_all()
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
            return

        # Step 4: æ˜¾ç¤ºç»Ÿè®¡å¹¶ç¡®è®¤
        print("\n Step 4: åŒæ­¥ç»Ÿè®¡")
        self._print_analysis_stats()

        pending_count = len(self.comparison.get('store_only', []))
        if pending_count == 0:
            print("\n æ‰€æœ‰é‚®ä»¶å·²åŒæ­¥ï¼Œæ— éœ€æ“ä½œï¼")
            return

        if limit:
            pending_count = min(pending_count, limit)
            print(f"\n å°†åªåŒæ­¥å‰ {limit} å°é‚®ä»¶")

        if not auto_confirm:
            confirm = input(f"\næ˜¯å¦å¼€å§‹åŒæ­¥ {pending_count} å°é‚®ä»¶åˆ° Notion? (y/n): ")
            if confirm.lower() != 'y':
                print("å·²å–æ¶ˆåŒæ­¥")
                return

        # Step 5: æ‰§è¡ŒåŒæ­¥
        print(f"\n Step 5: å¼€å§‹åŒæ­¥ {pending_count} å°é‚®ä»¶...")
        await self._sync_pending_emails(limit)

        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 60)
        print(" åŒæ­¥å®Œæˆ!")
        self._print_final_stats()
        print("=" * 60)

    async def analyze_only(self, skip_fetch: bool = False) -> AnalysisReport:
        """ä»…æ‰§è¡Œåˆ†æï¼Œä¸åŒæ­¥

        Args:
            skip_fetch: æ˜¯å¦è·³è¿‡ä» Mail.app è·å–é‚®ä»¶ï¼ˆä»…å¯¹æ¯”ç°æœ‰æ•°æ®ï¼‰

        Returns:
            AnalysisReport åˆ†ææŠ¥å‘Š
        """
        print("\n" + "=" * 60)
        print("MailAgent æ•°æ®åˆ†æ")
        print("=" * 60)

        # Step 1: æ£€æŸ¥ç¯å¢ƒ
        print("\n Step 1: æ£€æŸ¥ç¯å¢ƒ...")
        if not self._check_environment():
            return self.report

        if not skip_fetch:
            # Step 2: ä» AppleScript è·å–é‚®ä»¶
            print("\n Step 2: ä» Mail.app è·å–é‚®ä»¶...")
            await self._fetch_emails_from_applescript()
        else:
            print("\n Step 2: è·³è¿‡è·å–é‚®ä»¶ï¼ˆä½¿ç”¨ç°æœ‰ SyncStore æ•°æ®ï¼‰")

        # Step 3: ä¸€æ¬¡æŸ¥è¯¢å®Œæˆæ‰€æœ‰åˆ†æï¼ˆSyncStore vs Notion + Parent Itemï¼‰
        print("\n Step 3: åˆ†ææ•°æ®...")
        try:
            await self._analyze_all()
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
            return self.report

        # Step 4: æ˜¾ç¤ºç»Ÿè®¡
        print("\n Step 4: åˆ†æç»“æœ")
        self._print_analysis_stats()

        return self.report

    # ==================== ç¯å¢ƒæ£€æŸ¥ ====================

    def _check_environment(self) -> bool:
        """æ£€æŸ¥ç¯å¢ƒ"""
        checks = []

        # æ£€æŸ¥ SQLite é›·è¾¾
        radar_ok = self.radar.is_available()
        checks.append(("SQLite é›·è¾¾", radar_ok, "éœ€è¦ Full Disk Access æƒé™"))

        # æ£€æŸ¥é‚®ä»¶æ•°é‡
        email_counts = self.radar.get_email_count()
        for mailbox, count in email_counts.items():
            checks.append((f"{mailbox} é‚®ä»¶æ•°", count > 0, f"{count} å°"))

        # æ‰“å°æ£€æŸ¥ç»“æœ
        all_ok = True
        for name, ok, msg in checks:
            status = "âœ…" if ok else "âŒ"
            print(f"  {status} {name}: {msg if not ok or isinstance(msg, str) else 'OK'}")
            if not ok and name == "SQLite é›·è¾¾":
                all_ok = False

        return all_ok

    def _record_current_max_row_id(self):
        """è®°å½•å½“å‰ max_row_idï¼Œç”¨äºåç»­å¢é‡åŒæ­¥"""
        try:
            current_max = self.radar.get_current_max_row_id()
            if current_max:
                self.sync_store.set_last_max_row_id(current_max)
                print(f"  âœ… å·²è®°å½• max_row_id: {current_max}")
            else:
                print(f"  âš ï¸ æ— æ³•è·å– max_row_id")
        except Exception as e:
            print(f"  âš ï¸ è®°å½• max_row_id å¤±è´¥: {e}")

    # ==================== æ•°æ®è·å– ====================

    def _get_existing_count_by_mailbox(self) -> Dict[str, int]:
        """è·å– SyncStore ä¸­å„é‚®ç®±å·²æœ‰çš„é‚®ä»¶æ•°é‡"""
        conn = self.sync_store._get_connection()
        cursor = conn.cursor()
        try:
            cursor.execute("""
                SELECT mailbox, COUNT(*) as count
                FROM email_metadata
                GROUP BY mailbox
            """)
            return {row['mailbox']: row['count'] for row in cursor.fetchall()}
        except Exception as e:
            logger.warning(f"Failed to get existing counts: {e}")
            return {}
        finally:
            conn.close()

    async def _fetch_emails_from_applescript(self) -> bool:
        """ä» AppleScript è·å–é‚®ä»¶å¹¶ä¿å­˜åˆ° SyncStoreï¼ˆå¢é‡æ¨¡å¼ï¼‰

        é‡‡ç”¨æ—¶é—´é©±åŠ¨æ–¹å¼ï¼šè·å–é‚®ä»¶åˆ°ç¼“å­˜ï¼Œåç»­é€šè¿‡ SYNC_START_DATE è¿‡æ»¤éœ€åŒæ­¥çš„é‚®ä»¶ã€‚
        æ”¯æŒé€šè¿‡ mailbox_limits å‚æ•°é™åˆ¶æ¯ä¸ªé‚®ç®±çš„è·å–æ•°é‡ã€‚
        """
        total_fetched = 0

        # è·å– SyncStore ä¸­å·²æœ‰çš„é‚®ä»¶æ•°é‡ï¼ˆæŒ‰é‚®ç®±ï¼‰
        existing_counts = self._get_existing_count_by_mailbox()
        print(f"\n   SyncStore ä¸­å·²æœ‰é‚®ä»¶:")
        for mailbox in self.mailboxes:
            count = existing_counts.get(mailbox, 0)
            limit = self.mailbox_limits.get(mailbox, 0)
            limit_str = f" (ç›®æ ‡: {limit})" if limit > 0 else ""
            print(f"     - {mailbox}: {count} å°{limit_str}")

        for mailbox in self.mailboxes:
            existing = existing_counts.get(mailbox, 0)
            max_count = self.mailbox_limits.get(mailbox, 0)

            # è®¡ç®—éœ€è¦è·å–çš„æ•°é‡
            if max_count > 0:
                need_count = max(0, max_count - existing)
                if need_count == 0:
                    print(f"\n  âœ… {mailbox}: å·²æœ‰ {existing} å°ï¼Œå·²è¾¾ç›®æ ‡ {max_count}ï¼Œè·³è¿‡")
                    continue
                print(f"\n  è·å– {mailbox}ï¼ˆå·²æœ‰ {existing}ï¼Œéœ€è·å– {need_count} å°ï¼‰...")
            else:
                need_count = 0  # 0 = ä¸é™åˆ¶ï¼Œè·å–å…¨éƒ¨
                print(f"\n  è·å– {mailbox}ï¼ˆå·²æœ‰ {existing} å°ï¼Œæ— æ•°é‡é™åˆ¶ï¼‰...")

            # åˆ†æ‰¹è·å–é‚®ä»¶ï¼ˆä»é…ç½®è¯»å–æ‰¹é‡å¤§å°ï¼‰
            batch_size = settings.init_batch_size
            # ä»å·²æœ‰æ•°é‡ä½ç½®å¼€å§‹ï¼Œé¿å…é‡å¤è·å–
            offset = existing
            mailbox_total = 0

            print(f"    æ‰¹é‡å¤§å°: {batch_size}, èµ·å§‹ä½ç½®: {offset}")

            while True:
                # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°é™åˆ¶
                if need_count > 0 and mailbox_total >= need_count:
                    break

                # è®¡ç®—æœ¬æ‰¹æ¬¡è·å–æ•°é‡
                if need_count > 0:
                    remaining = need_count - mailbox_total
                    fetch_count = min(batch_size, remaining)
                else:
                    fetch_count = batch_size

                # æ˜¾ç¤ºå½“å‰è·å–è¿›åº¦
                print(f"    ğŸ“¥ è·å–ç¬¬ {offset + 1} - {offset + fetch_count} å°...", end=' ', flush=True)

                # ä½¿ç”¨ offset åˆ†é¡µè·å–
                import time
                start_time = time.time()
                emails = self.arm._fetch_emails_from_applescript(fetch_count, self.arm._get_mailbox_name(mailbox), offset=offset)
                elapsed = time.time() - start_time

                if not emails:
                    print(f"æ— æ›´å¤šé‚®ä»¶ ({elapsed:.1f}s)")
                    break

                print(f"è·å– {len(emails)} å° ({elapsed:.1f}s)", end=' ', flush=True)

                # ä¿å­˜åˆ° SyncStoreï¼ˆæ‰¹é‡è·å–å·²åŒ…å« thread_idï¼‰
                email_dicts = []
                for email in emails:
                    # thread_id å·²åœ¨æ‰¹é‡è·å–æ—¶æå–ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ message_id
                    thread_id = email.get('thread_id') or email['message_id'].strip('<>')

                    # AppleScript è¿”å›çš„æ—¶é—´æ˜¯æœ¬åœ°æ—¶é—´ï¼ˆæ— æ—¶åŒºï¼‰ï¼Œæ·»åŠ ç³»ç»Ÿæ—¶åŒº
                    date_received = email.get('date_received', '')
                    if date_received and '+' not in date_received and not date_received.endswith('Z'):
                        # æ·»åŠ ç³»ç»Ÿæ—¶åŒº
                        sys_tz = get_system_timezone()
                        tz_offset = sys_tz.utcoffset(None)
                        total_seconds = int(tz_offset.total_seconds())
                        hours, remainder = divmod(abs(total_seconds), 3600)
                        minutes = remainder // 60
                        sign = '+' if total_seconds >= 0 else '-'
                        tz_suffix = f"{sign}{hours:02d}:{minutes:02d}"
                        date_received = date_received + tz_suffix

                    email_dict = {
                        'message_id': email['message_id'],
                        'thread_id': thread_id,
                        'subject': email.get('subject', ''),
                        'sender': email.get('sender', ''),
                        'date_received': date_received,
                        'mailbox': mailbox,
                        'is_read': email.get('is_read', False),
                        'is_flagged': email.get('is_flagged', False),
                        'sync_status': 'pending'
                    }
                    email_dicts.append(email_dict)

                saved = self.sync_store.save_emails_batch(email_dicts)
                mailbox_total += saved
                total_fetched += saved

                # æ˜¾ç¤ºä¿å­˜ç»“æœ
                if saved < len(emails):
                    print(f"â†’ æ–°å¢ {saved} å° (è·³è¿‡ {len(emails) - saved} å°é‡å¤)")
                else:
                    print(f"â†’ æ–°å¢ {saved} å°")

                # å¦‚æœè·å–çš„æ•°é‡å°‘äºè¯·æ±‚æ•°é‡ï¼Œè¯´æ˜å·²åˆ°æœ«å°¾
                if len(emails) < fetch_count:
                    print(f"    å·²åˆ°è¾¾é‚®ä»¶æœ«å°¾")
                    break

                offset += fetch_count

            print(f"  âœ… {mailbox}: æœ¬æ¬¡æ–°å¢ {mailbox_total} å°ï¼Œæ€»è®¡ {existing + mailbox_total} å°")

        self.stats["fetched_from_applescript"] = total_fetched
        self.stats["saved_to_store"] = total_fetched

        # å¦‚æœæ²¡æœ‰æ–°è·å–çš„ï¼Œæ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        if total_fetched == 0:
            total_existing = sum(existing_counts.values())
            if total_existing > 0:
                print(f"\n  å·²æœ‰ {total_existing} å°é‚®ä»¶åœ¨ SyncStore ä¸­ï¼Œæ— éœ€é‡æ–°è·å–")
                return True

        return total_fetched > 0 or sum(existing_counts.values()) > 0

    def _get_all_store_emails(self) -> Dict[str, Dict]:
        """è·å– SyncStore ä¸­æ‰€æœ‰é‚®ä»¶

        Returns:
            {message_id: {subject, sender, date_received, thread_id, mailbox, sync_status}}
        """
        store_emails = {}
        conn = self.sync_store._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute("""
                SELECT message_id, subject, sender, date_received, thread_id,
                       mailbox, sync_status, notion_page_id
                FROM email_metadata
            """)

            for row in cursor.fetchall():
                store_emails[row['message_id']] = {
                    "subject": row['subject'],
                    "sender": row['sender'],
                    "date_received": row['date_received'],
                    "thread_id": row['thread_id'],
                    "mailbox": row['mailbox'],
                    "sync_status": row['sync_status'],
                    "notion_page_id": row['notion_page_id']
                }

        except Exception as e:
            logger.error(f"Failed to get store emails: {e}")
        finally:
            conn.close()

        return store_emails

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _extract_rich_text(self, props: dict, name: str) -> str:
        """ä» Notion properties æå– rich_text å€¼"""
        items = props.get(name, {}).get("rich_text", [])
        return items[0].get("text", {}).get("content", "") if items else ""

    def _extract_title(self, props: dict, name: str) -> str:
        """ä» Notion properties æå– title å€¼"""
        items = props.get(name, {}).get("title", [])
        return items[0].get("text", {}).get("content", "") if items else ""

    def _extract_date(self, props: dict, name: str) -> str:
        """ä» Notion properties æå– date å€¼"""
        date_obj = props.get(name, {}).get("date", {})
        return date_obj.get("start", "") if date_obj else ""

    def _extract_relation_id(self, props: dict, name: str) -> Optional[str]:
        """ä» Notion properties æå– relation çš„ç¬¬ä¸€ä¸ª ID"""
        relations = props.get(name, {}).get("relation", [])
        return relations[0].get("id") if relations else None

    async def _try_fetch_thread_head_from_mailapp(self, thread_id: str) -> bool:
        """å°è¯•ä» Mail.app è·å–çº¿ç¨‹å¤´å¹¶ä¿å­˜åˆ° SyncStore

        Args:
            thread_id: çº¿ç¨‹å¤´çš„ message_id

        Returns:
            bool: æ˜¯å¦æˆåŠŸè·å–å¹¶ä¿å­˜
        """
        # 1. æ£€æŸ¥æ˜¯å¦å·²æ ‡è®°ä¸º not_foundï¼ˆé¿å…é‡å¤è¯·æ±‚ï¼‰
        if self.sync_store.is_thread_head_not_found(thread_id):
            return False

        # 2. å°è¯•ä»ä¸¤ä¸ªé‚®ç®±è·å–
        full_email = None
        found_mailbox = None
        for mailbox in ['æ”¶ä»¶ç®±', 'å‘ä»¶ç®±']:
            full_email = self.arm.fetch_email_by_message_id(thread_id, mailbox)
            if full_email:
                found_mailbox = mailbox
                break

        if not full_email:
            # 3. è·å–å¤±è´¥ï¼Œæ ‡è®°ä¸º not_found
            self.sync_store.mark_thread_head_not_found(
                thread_id,
                note="Not found in Mail.app during analysis"
            )
            return False

        # 4. è·å–æˆåŠŸï¼Œä¿å­˜åˆ° SyncStore
        # å¤„ç†æ—¶åŒº
        date_received = full_email.get('date_received', '') or full_email.get('date', '')
        if date_received and '+' not in date_received and not date_received.endswith('Z'):
            sys_tz = get_system_timezone()
            tz_offset = sys_tz.utcoffset(None)
            total_seconds = int(tz_offset.total_seconds())
            hours, remainder = divmod(abs(total_seconds), 3600)
            minutes = remainder // 60
            sign = '+' if total_seconds >= 0 else '-'
            tz_suffix = f"{sign}{hours:02d}:{minutes:02d}"
            date_received = date_received + tz_suffix

        email_dict = {
            'message_id': thread_id,
            'thread_id': full_email.get('thread_id') or thread_id.strip('<>'),
            'subject': full_email.get('subject', ''),
            'sender': full_email.get('sender', ''),
            'date_received': date_received,
            'mailbox': found_mailbox,
            'is_read': full_email.get('is_read', False),
            'is_flagged': full_email.get('is_flagged', False),
            'sync_status': 'pending'
        }
        self.sync_store.save_email(email_dict)
        logger.info(f"Fetched thread head from Mail.app: {thread_id[:40]}...")
        return True

    # ==================== å¯¹æ¯”åˆ†æï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰ ====================

    async def _analyze_all(self):
        """ä¸€æ¬¡æŸ¥è¯¢å®Œæˆæ‰€æœ‰åˆ†æ

        åŒæ—¶ç”Ÿæˆï¼š
        - self.report.comparison: SyncStore vs Notion å¯¹æ¯”
        - self.report.parent_analysis: Parent Item çŠ¶æ€åˆ†æ
        """
        print("  æŸ¥è¯¢ Notion æ•°æ®åº“...")

        # 1. æŸ¥è¯¢ Notionï¼ˆä¸€æ¬¡ï¼‰
        notion_pages = []
        has_more = True
        start_cursor = None
        query_count = 0

        while has_more:
            query_params = {
                "database_id": self.notion_sync.client.email_db_id,
                "filter": {"property": "Message ID", "rich_text": {"is_not_empty": True}},
                "page_size": 100
            }
            if start_cursor:
                query_params["start_cursor"] = start_cursor

            results = await self.notion_sync.client.client.databases.query(**query_params)
            query_count += 1

            for page in results.get("results", []):
                props = page.get("properties", {})

                # æå–æ‰€æœ‰éœ€è¦çš„å­—æ®µ
                message_id = self._extract_rich_text(props, "Message ID")
                if not message_id:
                    continue

                notion_pages.append({
                    "page_id": page["id"],
                    "message_id": message_id,
                    "subject": self._extract_title(props, "Subject"),
                    "sender": props.get("From", {}).get("email", ""),
                    "date": self._extract_date(props, "Date"),
                    "thread_id": self._extract_rich_text(props, "Thread ID"),
                    "parent_item_id": self._extract_relation_id(props, "Parent Item"),
                    "has_parent": len(props.get("Parent Item", {}).get("relation", [])) > 0
                })

            has_more = results.get("has_more", False)
            start_cursor = results.get("next_cursor")

            if query_count % 10 == 0:
                print(f"    å·²æŸ¥è¯¢ {len(notion_pages)} å°...", end='\r')

        print(f"  Notion ä¸­æœ‰ {len(notion_pages)} å°é‚®ä»¶")

        # 2. æŸ¥è¯¢ SyncStore
        store_emails = self._get_all_store_emails()
        print(f"  SyncStore ä¸­æœ‰ {len(store_emails)} å°é‚®ä»¶")

        # 3. æ„å»ºç´¢å¼•
        notion_by_msg_id = {}
        for page in notion_pages:
            msg_id = page['message_id']
            notion_by_msg_id[msg_id] = page
            notion_by_msg_id[msg_id.strip('<>')] = page

        store_ids = set(store_emails.keys())
        notion_ids = set(notion_by_msg_id.keys())

        # 4. SyncStore vs Notion å¯¹æ¯” â†’ comparison
        self._build_comparison(store_emails, notion_by_msg_id, store_ids, notion_ids)

        # 5. Parent Item åˆ†æ â†’ parent_analysis
        await self._build_parent_analysis(notion_pages, notion_by_msg_id, store_emails)

    def _build_comparison(self, store_emails: Dict, notion_by_msg_id: Dict,
                          store_ids: set, notion_ids: set):
        """æ„å»º SyncStore vs Notion å¯¹æ¯”ç»“æœ"""
        comparison = self.report.comparison

        # é‡ç½®
        comparison['matched'] = []
        comparison['property_mismatch'] = []
        comparison['critical_mismatch'] = []
        comparison['store_only'] = []
        comparison['store_only_before_date'] = []
        comparison['notion_only'] = []

        sync_start_date = settings.sync_start_date

        # ä»…åœ¨ SyncStore
        for msg_id in (store_ids - notion_ids):
            store_data = store_emails.get(msg_id)
            if not store_data:
                continue
            date_received = (store_data.get('date_received') or '')[:10]

            if sync_start_date and date_received and date_received < sync_start_date:
                comparison['store_only_before_date'].append(msg_id)
            else:
                comparison['store_only'].append(msg_id)

        # ä»…åœ¨ Notionï¼ˆå»é‡å¤„ç†ï¼‰
        seen_notion_only = set()
        for msg_id in (notion_ids - store_ids):
            notion_data = notion_by_msg_id.get(msg_id)
            if notion_data and notion_data['message_id'] not in seen_notion_only:
                seen_notion_only.add(notion_data['message_id'])
                comparison['notion_only'].append((msg_id, notion_data))

        # ä¸¤è¾¹éƒ½æœ‰
        for msg_id in (store_ids & notion_ids):
            store_data = store_emails.get(msg_id)
            notion_data = notion_by_msg_id.get(msg_id)
            if not store_data or not notion_data:
                continue

            critical_reasons = []
            date_mismatch = False
            thread_mismatch = False

            # å¯¹æ¯” subject (strip å»æ‰å‰åæ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ŒåŒ…æ‹¬ tabã€æ¢è¡Œç­‰)
            store_subject = (store_data.get('subject') or '').strip()[:50]
            notion_subject = (notion_data.get('subject') or '').strip()[:50]
            if store_subject.lower() != notion_subject.lower():
                critical_reasons.append("subject ä¸åŒ")

            # å¯¹æ¯” sender
            store_sender = self._extract_email_address(store_data.get('sender', ''))
            notion_sender = self._extract_email_address(notion_data.get('sender', ''))
            if store_sender and notion_sender and store_sender.lower() != notion_sender.lower():
                critical_reasons.append(f"sender ä¸åŒ")

            # å¯¹æ¯” date
            store_date_str = store_data.get('date_received') or ''
            notion_date_str = notion_data.get('date') or ''
            if store_date_str and notion_date_str:
                if not dates_match(store_date_str, notion_date_str, tolerance_seconds=120):
                    date_mismatch = True

            # æ£€æŸ¥æ—¶åŒº
            tz_mismatch = notion_date_str and not is_notion_date_beijing_tz(notion_date_str)

            # å¯¹æ¯” thread_id
            store_thread = store_data.get('thread_id', '')
            notion_thread = notion_data.get('thread_id', '')
            if store_thread and store_thread != notion_thread:
                thread_mismatch = True

            # åˆ†ç±»
            if critical_reasons:
                comparison['critical_mismatch'].append((msg_id, store_data, notion_data, critical_reasons))
            elif date_mismatch or thread_mismatch or tz_mismatch:
                comparison['property_mismatch'].append((msg_id, store_data, notion_data))
            else:
                comparison['matched'].append((msg_id, store_data, notion_data))

    async def _build_parent_analysis(self, notion_pages: List[Dict],
                                      notion_by_msg_id: Dict, store_emails: Dict):
        """æ„å»º Parent Item åˆ†æç»“æœï¼ˆæ–°æ¶æ„ï¼šæœ€æ–°é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹ï¼‰

        æ–°é€»è¾‘ï¼š
        1. æŒ‰ thread_id åˆ†ç»„æ‰€æœ‰é‚®ä»¶
        2. æ¯ä¸ªçº¿ç¨‹ä¸­æœ€æ–°çš„é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹ï¼ˆä¸åº”æœ‰ Parent Itemï¼‰
        3. å…¶ä»–é‚®ä»¶çš„ Parent Item åº”æŒ‡å‘æœ€æ–°é‚®ä»¶
        """
        analysis = self.report.parent_analysis

        # é‡ç½®
        analysis['total'] = len(notion_pages)
        analysis['threads'] = {}  # æ–°å¢ï¼šæŒ‰çº¿ç¨‹åˆ†ç»„çš„åˆ†æç»“æœ
        analysis['summary'] = {
            'total_threads': 0,
            'single_email_threads': 0,  # åªæœ‰ä¸€å°é‚®ä»¶çš„çº¿ç¨‹
            'multi_email_threads': 0,   # å¤šå°é‚®ä»¶çš„çº¿ç¨‹
            'correct': 0,               # å…³ç³»æ­£ç¡®çš„é‚®ä»¶
            'need_update': 0,           # éœ€è¦æ›´æ–°çš„é‚®ä»¶
        }

        print("  åˆ†æ Parent Item çŠ¶æ€ï¼ˆæ–°æ¶æ„ï¼šæœ€æ–°é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹ï¼‰...")

        # 1. æŒ‰ thread_id åˆ†ç»„
        threads_map = {}  # thread_id -> List[page_data]
        no_thread_emails = []  # æ²¡æœ‰ thread_id çš„é‚®ä»¶

        for page_data in notion_pages:
            thread_id = page_data.get('thread_id', '').strip('<>')
            message_id = page_data.get('message_id', '').strip('<>')

            # æ²¡æœ‰ thread_id æˆ– thread_id == message_id çš„é‚®ä»¶ï¼Œè§†ä¸ºç‹¬ç«‹é‚®ä»¶
            if not thread_id or thread_id == message_id:
                no_thread_emails.append(page_data)
            else:
                if thread_id not in threads_map:
                    threads_map[thread_id] = []
                threads_map[thread_id].append(page_data)

        # ä¹Ÿè¦æŠŠçº¿ç¨‹å¤´åŠ å…¥åˆ°å¯¹åº”çš„çº¿ç¨‹ç»„
        # çº¿ç¨‹å¤´æ˜¯ message_id == thread_id çš„é‚®ä»¶ï¼Œä½†æˆ‘ä»¬éœ€è¦æŠŠå®ƒåŠ å…¥åˆ°ä»¥å®ƒä¸º thread_id çš„çº¿ç¨‹ä¸­
        for page_data in no_thread_emails:
            message_id = page_data.get('message_id', '').strip('<>')
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»¥æ­¤ä¸º thread_id çš„çº¿ç¨‹å­˜åœ¨
            if message_id in threads_map:
                threads_map[message_id].append(page_data)

        print(f"    çº¿ç¨‹åˆ†ç»„å®Œæˆ: {len(threads_map)} ä¸ªçº¿ç¨‹, {len(no_thread_emails)} å°ç‹¬ç«‹é‚®ä»¶")

        # 2. åˆ†ææ¯ä¸ªçº¿ç¨‹
        for thread_id, emails in threads_map.items():
            if len(emails) == 0:
                continue

            # æŒ‰æ—¥æœŸæ’åºï¼ˆé™åºï¼Œæœ€æ–°åœ¨å‰ï¼‰
            emails_sorted = sorted(
                emails,
                key=lambda x: x.get('date', '') or '',
                reverse=True
            )

            latest_email = emails_sorted[0]
            latest_page_id = latest_email['page_id']
            other_emails = emails_sorted[1:]

            thread_analysis = {
                'thread_id': thread_id,
                'latest_page_id': latest_page_id,
                'latest_message_id': latest_email.get('message_id', ''),
                'latest_subject': latest_email.get('subject', '')[:50],
                'latest_date': latest_email.get('date', ''),
                'latest_current_parent': latest_email.get('parent_item_id'),
                'other_emails': [],
                'need_update_latest': False,  # æœ€æ–°é‚®ä»¶æ˜¯å¦éœ€è¦æ¸…ç©º Parent
                'sub_items_to_set': []  # éœ€è¦è®¾ç½®ä¸º Sub-item çš„ page_id åˆ—è¡¨
            }

            # æ£€æŸ¥æœ€æ–°é‚®ä»¶æ˜¯å¦æœ‰é”™è¯¯çš„ Parent Itemï¼ˆåº”è¯¥æ²¡æœ‰ï¼‰
            if latest_email.get('parent_item_id'):
                thread_analysis['need_update_latest'] = True
                analysis['summary']['need_update'] += 1
            else:
                analysis['summary']['correct'] += 1

            # åˆ†æå…¶ä»–é‚®ä»¶
            for email in other_emails:
                email_info = {
                    'page_id': email['page_id'],
                    'message_id': email.get('message_id', ''),
                    'subject': email.get('subject', '')[:50],
                    'date': email.get('date', ''),
                    'current_parent': email.get('parent_item_id'),
                    'need_update': False
                }

                # æ£€æŸ¥ Parent Item æ˜¯å¦æ­£ç¡®æŒ‡å‘æœ€æ–°é‚®ä»¶
                if email.get('parent_item_id') != latest_page_id:
                    email_info['need_update'] = True
                    thread_analysis['sub_items_to_set'].append(email['page_id'])
                    analysis['summary']['need_update'] += 1
                else:
                    analysis['summary']['correct'] += 1

                thread_analysis['other_emails'].append(email_info)

            analysis['threads'][thread_id] = thread_analysis

        # 3. ç»Ÿè®¡ç‹¬ç«‹é‚®ä»¶ï¼ˆæ²¡æœ‰çº¿ç¨‹å…³ç³»çš„ï¼‰
        for email in no_thread_emails:
            message_id = email.get('message_id', '').strip('<>')
            # å¦‚æœè¿™ä¸ªé‚®ä»¶ä¸æ˜¯æŸä¸ªçº¿ç¨‹çš„çº¿ç¨‹å¤´ï¼Œå®ƒå°±æ˜¯çœŸæ­£çš„ç‹¬ç«‹é‚®ä»¶
            if message_id not in threads_map:
                # ç‹¬ç«‹é‚®ä»¶ä¸åº”è¯¥æœ‰ Parent Item
                if email.get('parent_item_id'):
                    # éœ€è¦æ¸…ç©º
                    analysis['summary']['need_update'] += 1
                else:
                    analysis['summary']['correct'] += 1

        # æ›´æ–°ç»Ÿè®¡
        analysis['summary']['total_threads'] = len(threads_map)
        analysis['summary']['single_email_threads'] = sum(
            1 for t in analysis['threads'].values() if len(t.get('other_emails', [])) == 0
        )
        analysis['summary']['multi_email_threads'] = sum(
            1 for t in analysis['threads'].values() if len(t.get('other_emails', [])) > 0
        )

        print(f"    åˆ†æå®Œæˆ: {analysis['summary']['total_threads']} ä¸ªçº¿ç¨‹")
        print(f"      - å•é‚®ä»¶çº¿ç¨‹: {analysis['summary']['single_email_threads']} ä¸ª")
        print(f"      - å¤šé‚®ä»¶çº¿ç¨‹: {analysis['summary']['multi_email_threads']} ä¸ª")
        print(f"      - å…³ç³»æ­£ç¡®: {analysis['summary']['correct']} å°")
        print(f"      - éœ€è¦æ›´æ–°: {analysis['summary']['need_update']} å°")

    def _extract_email_address(self, sender: str) -> str:
        """ä» sender å­—ç¬¦ä¸²ä¸­æå–é‚®ç®±åœ°å€

        æ”¯æŒæ ¼å¼:
        - "Name" <email@example.com>
        - Name <email@example.com>
        - email@example.com
        """
        import re
        if not sender:
            return ""

        # å°è¯•ä» <email> æ ¼å¼ä¸­æå–
        match = re.search(r'<([^>]+)>', sender)
        if match:
            return match.group(1).strip().lower()

        # å¦‚æœæ²¡æœ‰å°–æ‹¬å·ï¼Œæ£€æŸ¥æ˜¯å¦æœ¬èº«å°±æ˜¯é‚®ç®±
        if '@' in sender:
            return sender.strip().lower()

        return ""

    # ==================== ç»Ÿè®¡è¾“å‡º ====================

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ä» Mail.app è·å–:  {self.stats['fetched_from_applescript']:>6} å°       â”‚
  â”‚ å·²åœ¨ Notion:       {self.stats['already_in_notion']:>6} å°       â”‚
  â”‚ å¾…åŒæ­¥:            {self.stats['pending_sync']:>6} å°       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)

    def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        print(f"""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æˆåŠŸåŒæ­¥:  {self.stats['synced']:>6} å°              â”‚
  â”‚ åŒæ­¥å¤±è´¥:  {self.stats['failed']:>6} å°              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)

    def _print_analysis_stats(self):
        """æ‰“å°åˆå¹¶åçš„åˆ†æç»Ÿè®¡"""
        comp = self.report.comparison
        pa = self.report.parent_analysis
        summary = pa.get('summary', {})
        threads = pa.get('threads', {})

        # è®¡ç®—éœ€è¦æ›´æ–°çš„çº¿ç¨‹æ•°
        threads_need_update = sum(
            1 for t in threads.values()
            if t.get('need_update_latest') or t.get('sub_items_to_set')
        )

        print(f"""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        åˆ†æç»“æœ                                 â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ ã€SyncStore vs Notion å¯¹æ¯”ã€‘                                    â”‚
  â”‚   âœ… å®Œå…¨åŒ¹é…ï¼ˆå·²åŒæ­¥ï¼‰:              {len(comp.get('matched', [])):>6} å°                â”‚
  â”‚   âš ï¸  å±æ€§ä¸åŒï¼ˆdate/thread_idï¼‰:     {len(comp.get('property_mismatch', [])):>6} å°                â”‚
  â”‚   âŒ å…³é”®ä¿¡æ¯ä¸åŒï¼ˆéœ€é‡æ–°åŒæ­¥ï¼‰:      {len(comp.get('critical_mismatch', [])):>6} å°                â”‚
  â”‚   ğŸ“¤ å¾…åŒæ­¥ï¼ˆä»…åœ¨ SyncStoreï¼‰:        {len(comp.get('store_only', [])):>6} å°                â”‚
  â”‚   ğŸ“… æ—©äºåŒæ­¥æ—¥æœŸï¼ˆä»…ç¼“å­˜ï¼‰:          {len(comp.get('store_only_before_date', [])):>6} å°                â”‚
  â”‚   â“ ä»…åœ¨ Notion:                     {len(comp.get('notion_only', [])):>6} å°                â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ ã€Parent Item çŠ¶æ€ã€‘æ–°æ¶æ„ï¼šæœ€æ–°é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹                    â”‚
  â”‚   æ€»é‚®ä»¶æ•°: {pa.get('total', 0):>6} å°                                        â”‚
  â”‚   æ€»çº¿ç¨‹æ•°: {summary.get('total_threads', 0):>6} ä¸ª                                        â”‚
  â”‚     - å•é‚®ä»¶çº¿ç¨‹: {summary.get('single_email_threads', 0):>6} ä¸ª                                â”‚
  â”‚     - å¤šé‚®ä»¶çº¿ç¨‹: {summary.get('multi_email_threads', 0):>6} ä¸ª                                â”‚
  â”‚   å…³ç³»çŠ¶æ€:                                                     â”‚
  â”‚     âœ… å·²æ­£ç¡®: {summary.get('correct', 0):>6} å°                                        â”‚
  â”‚     âš ï¸  éœ€æ›´æ–°: {summary.get('need_update', 0):>6} å°                                        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)

        # éœ€è¦æ“ä½œçš„ç»Ÿè®¡
        need_fix_props = len(comp.get('property_mismatch', []))
        need_fix_critical = len(comp.get('critical_mismatch', []))
        need_sync_new = len(comp.get('store_only', []))

        print(f"  ğŸ“Œ éœ€è¦æ“ä½œ:")
        print(f"     - ä¿®å¤å±æ€§ (fix-properties): {need_fix_props} å°")
        print(f"     - é‡æ–°åŒæ­¥ (fix-critical): {need_fix_critical} å°")
        print(f"     - åŒæ­¥æ–°é‚®ä»¶ (sync-new): {need_sync_new} å°")
        print(f"     - æ›´æ–° Parent Item (update-all-parents): {threads_need_update} ä¸ªçº¿ç¨‹")

        # æ ‡è®°å·²åŒ¹é…çš„ä¸º synced
        for message_id, store_data, notion_data in comp.get('matched', []):
            self.sync_store.mark_synced(message_id, notion_data['page_id'], None)

        if comp.get('matched'):
            print(f"\n  âœ… å·²æ ‡è®° {len(comp['matched'])} å°ä¸ºå·²åŒæ­¥")

    # ==================== åŒæ­¥æ“ä½œ ====================

    async def _sync_pending_emails(self, limit: int = None):
        """åŒæ­¥æ‰€æœ‰å¾…åŒæ­¥çš„é‚®ä»¶"""
        pending_emails = self.sync_store.get_pending_emails(limit=limit or 10000)

        total = len(pending_emails)
        for i, email_meta in enumerate(pending_emails, 1):
            message_id = email_meta['message_id']
            subject = email_meta.get('subject', '')[:40]

            print(f"\n  [{i}/{total}] {subject}...")

            try:
                # è·å–å®Œæ•´é‚®ä»¶å†…å®¹
                mailbox = email_meta.get('mailbox', 'æ”¶ä»¶ç®±')
                full_email = self.arm.fetch_email_by_message_id(message_id, mailbox)

                if not full_email:
                    print(f"    âŒ æ— æ³•è·å–é‚®ä»¶å†…å®¹")
                    self.sync_store.mark_failed(message_id, "Failed to fetch content")
                    self.stats["failed"] += 1
                    continue

                # æ„å»º Email å¯¹è±¡
                email_obj = await self._build_email_object(full_email, mailbox)
                if not email_obj:
                    print(f"    âŒ æ— æ³•è§£æé‚®ä»¶")
                    self.sync_store.mark_failed(message_id, "Failed to parse email")
                    self.stats["failed"] += 1
                    continue

                # åŒæ­¥åˆ° Notion
                page_id = await self.notion_sync.create_email_page_v2(
                    email_obj
                )

                if page_id:
                    self.sync_store.mark_synced(message_id, page_id)
                    self.stats["synced"] += 1
                    print(f"    âœ… åŒæ­¥æˆåŠŸ")
                else:
                    self.sync_store.mark_failed(message_id, "Notion returned None")
                    self.stats["failed"] += 1
                    print(f"    âŒ åŒæ­¥å¤±è´¥")

            except Exception as e:
                logger.error(f"Sync error for {message_id}: {e}")
                self.sync_store.mark_failed(message_id, str(e))
                self.stats["failed"] += 1
                print(f"    âŒ é”™è¯¯: {e}")

    async def _sync_specific_emails(self, message_ids: List[str]):
        """åŒæ­¥æŒ‡å®šçš„é‚®ä»¶åˆ—è¡¨ï¼ˆç”¨äºä¿®å¤æ“ä½œï¼‰"""
        total = len(message_ids)
        success = 0
        failed = 0
        not_found = 0

        for i, message_id in enumerate(message_ids, 1):
            # è·å–é‚®ä»¶å…ƒæ•°æ®
            email_meta = self.sync_store.get_email(message_id)
            if not email_meta:
                print(f"  [{i}/{total}] âŒ æœªæ‰¾åˆ°é‚®ä»¶å…ƒæ•°æ®: {message_id[:30]}...")
                failed += 1
                continue

            subject = email_meta.get('subject', '')[:40]
            print(f"  [{i}/{total}] {subject}...", end='\r')

            try:
                mailbox = email_meta.get('mailbox', 'æ”¶ä»¶ç®±')
                full_email = self.arm.fetch_email_by_message_id(message_id, mailbox)

                if not full_email:
                    # é‚®ä»¶åœ¨ Mail.app ä¸­æ‰¾ä¸åˆ°ï¼Œåˆ é™¤è®°å½•
                    self.sync_store.delete_email(message_id)
                    not_found += 1
                    continue

                email_obj = await self._build_email_object(full_email, mailbox)
                if not email_obj:
                    self.sync_store.mark_failed(message_id, "Failed to parse email")
                    failed += 1
                    continue

                page_id = await self.notion_sync.create_email_page_v2(
                    email_obj
                )

                if page_id:
                    self.sync_store.mark_synced(message_id, page_id)
                    success += 1
                else:
                    self.sync_store.mark_failed(message_id, "Notion returned None")
                    failed += 1

            except Exception as e:
                logger.error(f"Sync error for {message_id}: {e}")
                self.sync_store.mark_failed(message_id, str(e))
                failed += 1

        return success, failed, not_found

    async def _fetch_and_sync_thread_head(self, thread_id: str) -> Optional[str]:
        """[å·²åºŸå¼ƒ] è·å–å¹¶åŒæ­¥çº¿ç¨‹å¤´é‚®ä»¶

        æ–°æ¶æ„ä½¿ç”¨æœ€æ–°é‚®ä»¶ä½œä¸ºæ¯èŠ‚ç‚¹ï¼Œä¸å†éœ€è¦æŸ¥æ‰¾å’ŒåŒæ­¥çº¿ç¨‹å¤´ã€‚
        çº¿ç¨‹å…³ç³»ç”± NotionSync._handle_thread_relations() è‡ªåŠ¨å¤„ç†ã€‚

        ä¿ç•™æ­¤æ–¹æ³•ä»…ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…ä¸å†è¢«è°ƒç”¨ã€‚

        Args:
            thread_id: çº¿ç¨‹æ ‡è¯†ï¼ˆé€šå¸¸æ˜¯åŸå§‹é‚®ä»¶çš„ message_idï¼‰

        Returns:
            Noneï¼ˆä¸å†æ‰§è¡Œä»»ä½•æ“ä½œï¼‰
        """
        logger.debug(f"[DEPRECATED] _fetch_and_sync_thread_head called for: {thread_id[:50]}...")
        return None

    async def _fetch_and_sync_thread_head_legacy(self, thread_id: str) -> Optional[str]:
        """[å·²åºŸå¼ƒ - æ—§å®ç°å¤‡ä»½] è·å–å¹¶åŒæ­¥çº¿ç¨‹å¤´é‚®ä»¶

        ä» SyncStore ç¼“å­˜ä¸­æŸ¥æ‰¾åŒ thread_id æœ€æ—©çš„é‚®ä»¶å¹¶åŒæ­¥ã€‚

        ä¼˜å…ˆçº§ï¼š
        1. æ£€æŸ¥çº¿ç¨‹å¤´æ˜¯å¦å·²åŒæ­¥åˆ° Notionï¼ˆé€šè¿‡ message_id æŸ¥æ‰¾ï¼‰
        2. åœ¨ SyncStore ç¼“å­˜ä¸­æŸ¥æ‰¾åŒ thread_id æœ€æ—©çš„é‚®ä»¶å¹¶åŒæ­¥

        æ³¨æ„ï¼šä¸å†ä» Mail.app å®æ—¶è·å–çº¿ç¨‹å¤´ï¼Œä¾èµ–é¢„å…ˆå†™å…¥çš„ç¼“å­˜ã€‚
        å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä¼šç”± create_email_page_v2 çš„é™çº§æ–¹æ¡ˆå¤„ç†ï¼ˆä½¿ç”¨ Notion ä¸­æœ€æ—©çš„åŒçº¿ç¨‹é‚®ä»¶ï¼‰ã€‚

        Args:
            thread_id: çº¿ç¨‹æ ‡è¯†ï¼ˆé€šå¸¸æ˜¯åŸå§‹é‚®ä»¶çš„ message_idï¼‰

        Returns:
            çº¿ç¨‹å¤´é‚®ä»¶çš„ page_idï¼Œæ‰¾ä¸åˆ°è¿”å› None
        """
        # 1. æ£€æŸ¥çº¿ç¨‹å¤´æ˜¯å¦å·²åœ¨ SyncStore ä¸”å·²åŒæ­¥
        existing = self.sync_store.get_email(thread_id)
        if existing and existing.get('sync_status') == 'synced':
            return existing.get('notion_page_id')

        # 2. åœ¨ SyncStore ç¼“å­˜ä¸­æŸ¥æ‰¾åŒ thread_id æœ€æ—©çš„é‚®ä»¶
        earliest = self.sync_store.get_earliest_email_by_thread_id(thread_id)
        if earliest:
            earliest_msg_id = earliest.get('message_id')

            # å¦‚æœæœ€æ—©çš„é‚®ä»¶å·²åŒæ­¥ï¼Œç›´æ¥è¿”å›
            if earliest.get('sync_status') == 'synced':
                logger.info(f"Found synced earliest thread member in cache: {earliest_msg_id[:40]}...")
                return earliest.get('notion_page_id')

            # æœ€æ—©çš„é‚®ä»¶æœªåŒæ­¥ï¼Œå°è¯•åŒæ­¥å®ƒï¼ˆè·³è¿‡ Parent Item æŸ¥æ‰¾é¿å…é€’å½’ï¼‰
            logger.info(f"Found unsynced earliest thread member in cache, syncing: {earliest_msg_id[:40]}...")
            mailbox = earliest.get('mailbox', 'æ”¶ä»¶ç®±')

            try:
                full_email = self.arm.fetch_email_by_message_id(earliest_msg_id, mailbox)
                if full_email:
                    email_obj = await self._build_email_object(full_email, mailbox)
                    if email_obj:
                        # ä½¿ç”¨ skip_parent_lookup=True é¿å…é€’å½’
                        page_id = await self.notion_sync.create_email_page_v2(
                            email_obj,
                            skip_parent_lookup=True  # å…³é”®ï¼šè·³è¿‡ Parent Item æŸ¥æ‰¾
                        )

                        if page_id:
                            self.sync_store.mark_synced(earliest_msg_id, page_id)
                            logger.info(f"Synced earliest thread member: {earliest_msg_id[:40]}... -> {page_id}")
                            return page_id
            except Exception as e:
                logger.warning(f"Failed to sync earliest thread member {earliest_msg_id[:40]}...: {e}")

        # ç¼“å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å› Noneï¼ˆç”± create_email_page_v2 çš„é™çº§æ–¹æ¡ˆå¤„ç†ï¼‰
        logger.info(f"Thread head not found in cache: {thread_id[:50]}...")
        return None

    async def _sync_email_by_message_id(self, message_id: str, mailbox: str) -> Optional[str]:
        """åŒæ­¥æŒ‡å®š message_id çš„é‚®ä»¶åˆ° Notion

        ç”¨äºé™çº§æ–¹æ¡ˆï¼šåŒæ­¥ SyncStore ä¸­çš„é‚®ä»¶ä½œä¸º Parent Itemã€‚
        å¦‚æœé‚®ä»¶ä¸åœ¨ SyncStore ä¸­ï¼Œä¼šå…ˆä¿å­˜å…ƒæ•°æ®å†åŒæ­¥ã€‚

        Args:
            message_id: é‚®ä»¶çš„ message_id
            mailbox: é‚®ç®±åç§°

        Returns:
            åŒæ­¥æˆåŠŸè¿”å› page_idï¼Œå¤±è´¥è¿”å› None
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²åŒæ­¥
            existing = self.sync_store.get_email(message_id)
            if existing and existing.get('sync_status') == 'synced':
                return existing.get('notion_page_id')

            # ä» Mail.app è·å–å®Œæ•´é‚®ä»¶
            full_email = self.arm.fetch_email_by_message_id(message_id, mailbox)
            if not full_email:
                logger.warning(f"Email not found in Mail.app: {message_id[:40]}...")
                return None

            # å¦‚æœ SyncStore ä¸­æ²¡æœ‰è¿™å°é‚®ä»¶ï¼Œå…ˆä¿å­˜å…ƒæ•°æ®
            if not existing:
                # æ·»åŠ ç³»ç»Ÿæ—¶åŒºåˆ° AppleScript è¿”å›çš„æœ¬åœ°æ—¶é—´
                date_received = full_email.get('date_received', '') or full_email.get('date', '')
                if date_received and '+' not in date_received and not date_received.endswith('Z'):
                    sys_tz = get_system_timezone()
                    tz_offset = sys_tz.utcoffset(None)
                    total_seconds = int(tz_offset.total_seconds())
                    hours, remainder = divmod(abs(total_seconds), 3600)
                    minutes = remainder // 60
                    sign = '+' if total_seconds >= 0 else '-'
                    tz_suffix = f"{sign}{hours:02d}:{minutes:02d}"
                    date_received = date_received + tz_suffix

                email_dict = {
                    'message_id': message_id,
                    'thread_id': full_email.get('thread_id') or message_id.strip('<>'),
                    'subject': full_email.get('subject', ''),
                    'sender': full_email.get('sender', ''),
                    'date_received': date_received,
                    'mailbox': mailbox,
                    'is_read': full_email.get('is_read', False),
                    'is_flagged': full_email.get('is_flagged', False),
                    'sync_status': 'pending'
                }
                self.sync_store.save_email(email_dict)
                logger.info(f"Saved email to SyncStore before sync: {message_id[:40]}...")

            # æ„å»º Email å¯¹è±¡
            email_obj = await self._build_email_object(full_email, mailbox)
            if not email_obj:
                logger.warning(f"Failed to build email object: {message_id[:40]}...")
                return None

            # åŒæ­¥åˆ° Notionï¼ˆè·³è¿‡ Parent Item æŸ¥æ‰¾é¿å…é€’å½’ï¼‰
            page_id = await self.notion_sync.create_email_page_v2(
                email_obj,
                skip_parent_lookup=True
            )

            if page_id:
                self.sync_store.mark_synced(message_id, page_id)
                logger.info(f"Synced email for fallback: {message_id[:40]}... -> {page_id}")
                return page_id

        except Exception as e:
            logger.error(f"Failed to sync email {message_id[:40]}...: {e}")

        return None

    async def _build_email_object(self, full_email: Dict, mailbox: str) -> Optional[Email]:
        """ä½¿ç”¨ EmailReader æ„å»ºå®Œæ•´çš„ Email å¯¹è±¡ï¼ˆåŒ…å«é™„ä»¶å’Œå›¾ç‰‡å¤„ç†ï¼‰

        ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨å·²è·å–çš„ source è§£æï¼Œé¿å…é‡å¤è°ƒç”¨ AppleScript
        """
        try:
            source = full_email.get('source', '')
            if not source:
                logger.warning("Email source is empty")
                return None

            # ç›´æ¥è§£æå·²è·å–çš„ sourceï¼Œä¸å†è°ƒç”¨ AppleScript
            email_obj = self.email_reader.parse_email_source(
                source=source,
                message_id=full_email.get('message_id'),
                is_read=full_email.get('is_read', False),
                is_flagged=full_email.get('is_flagged', False)
            )

            if email_obj:
                # è®¾ç½®é‚®ç®±ç±»å‹
                email_obj.mailbox = mailbox
                # å¦‚æœ AppleScript å·²ç»æå–äº† thread_idï¼Œä½¿ç”¨å®ƒ
                if full_email.get('thread_id'):
                    email_obj.thread_id = full_email.get('thread_id')

            return email_obj

        except Exception as e:
            logger.error(f"Failed to build Email object: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    # ==================== ä¿®å¤æ“ä½œ ====================

    async def fix_properties(self, auto_confirm: bool = False):
        """ä¿®å¤å±æ€§ä¸åŒçš„é‚®ä»¶ï¼ˆæ›´æ–° Notion çš„ Date å’Œ Thread IDï¼‰"""
        items = self.comparison.get('property_mismatch', [])
        if not items:
            print("âœ… æ²¡æœ‰éœ€è¦ä¿®å¤å±æ€§çš„é‚®ä»¶")
            return

        print(f"\n ä¿®å¤å±æ€§ä¸åŒçš„é‚®ä»¶: {len(items)} å°")

        if not auto_confirm:
            confirm = input(f"ç¡®è®¤æ›´æ–° {len(items)} å°é‚®ä»¶çš„ Date/Thread ID? (y/n): ")
            if confirm.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return

        success = 0
        failed = 0

        for i, (message_id, store_data, notion_data) in enumerate(items, 1):
            page_id = notion_data['page_id']

            print(f"  [{i}/{len(items)}] æ›´æ–°å±æ€§...", end='\r')

            try:
                # æ„å»ºéœ€è¦æ›´æ–°çš„å±æ€§
                properties_to_update = {}

                # æ£€æŸ¥å¹¶æ›´æ–° Dateï¼ˆç»Ÿä¸€è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼‰
                store_date_str = store_data.get('date_received', '')
                notion_date_str = notion_data.get('date', '')

                # éœ€è¦æ›´æ–°çš„æƒ…å†µï¼š
                # 1. æ—¥æœŸæ—¶é—´ä¸åŒ¹é…ï¼ˆè¶…è¿‡å®¹å·®ï¼‰
                # 2. Notion æ—¶åŒºä¸æ˜¯åŒ—äº¬æ—¶é—´
                need_date_update = False
                if store_date_str:
                    if not dates_match(store_date_str, notion_date_str, tolerance_seconds=120):
                        need_date_update = True
                    elif not is_notion_date_beijing_tz(notion_date_str):
                        need_date_update = True

                if need_date_update:
                    # è§£æ SyncStore æ—¶é—´å¹¶è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
                    store_dt = parse_datetime_with_tz(store_date_str)
                    if store_dt:
                        beijing_dt = store_dt.astimezone(BEIJING_TZ)
                        properties_to_update["Date"] = {"date": {"start": beijing_dt.isoformat()}}
                    else:
                        # æ— æ³•è§£ææ—¥æœŸï¼Œè®°å½•è­¦å‘Š
                        logger.warning(f"Cannot parse date '{store_date_str}' for {message_id[:40]}...")

                # æ£€æŸ¥å¹¶æ›´æ–° Thread ID
                store_thread = store_data.get('thread_id', '')
                notion_thread = notion_data.get('thread_id', '')
                if store_thread and store_thread != notion_thread:
                    properties_to_update["Thread ID"] = {
                        "rich_text": [{"text": {"content": store_thread[:1999]}}]
                    }

                # æ‰§è¡Œæ›´æ–°
                if properties_to_update:
                    await self.notion_sync.client.client.pages.update(
                        page_id=page_id,
                        properties=properties_to_update
                    )
                    self.sync_store.mark_synced(message_id, page_id, None)
                    success += 1
                else:
                    # æ²¡æœ‰å¯æ›´æ–°çš„å±æ€§ï¼ˆå¯èƒ½æ˜¯æ—¥æœŸè§£æå¤±è´¥ï¼‰
                    logger.warning(f"No properties to update for {message_id[:40]}... (date parse failed?)")
                    failed += 1
            except Exception as e:
                logger.error(f"Failed to update properties for {message_id}: {e}")
                failed += 1

        print(f"\nâœ… å±æ€§æ›´æ–°å®Œæˆ: æˆåŠŸ {success} å°, å¤±è´¥ {failed} å°")

    async def fix_critical_mismatch(self, auto_confirm: bool = False):
        """ä¿®å¤å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶ï¼ˆåˆ é™¤æ—§é¡µé¢ï¼Œé‡æ–°åŒæ­¥ï¼‰"""
        items = self.comparison.get('critical_mismatch', [])
        if not items:
            print("âœ… æ²¡æœ‰å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶")
            return

        print(f"\n ä¿®å¤å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶: {len(items)} å°")
        print("  è¿™å°†åˆ é™¤ Notion ä¸­çš„æ—§é¡µé¢å¹¶é‡æ–°åŒæ­¥")

        if not auto_confirm:
            # æ˜¾ç¤ºè¯¦æƒ…
            print("\n  å°†å¤„ç†ä»¥ä¸‹é‚®ä»¶:")
            for _, store_data, _, reasons in items[:10]:
                print(f"    - {store_data.get('subject', '')[:40]}...")
                print(f"      åŸå› : {', '.join(reasons)}")

            if len(items) > 10:
                print(f"    ... è¿˜æœ‰ {len(items) - 10} å°")

            confirm = input(f"\nç¡®è®¤é‡æ–°åŒæ­¥ {len(items)} å°é‚®ä»¶? (y/n): ")
            if confirm.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return

        success = 0
        failed = 0
        not_found = 0  # é‚®ä»¶åœ¨ Mail.app ä¸­æ‰¾ä¸åˆ°

        for i, (message_id, store_data, notion_data, _) in enumerate(items, 1):
            page_id = notion_data['page_id']
            subject = store_data.get('subject', '')[:40]

            print(f"  [{i}/{len(items)}] é‡æ–°åŒæ­¥: {subject}...", end='\r')

            try:
                # 1. å½’æ¡£ï¼ˆåˆ é™¤ï¼‰æ—§é¡µé¢ï¼ˆå¦‚æœå°šæœªå½’æ¡£ï¼‰
                try:
                    await self.notion_sync.client.client.pages.update(
                        page_id=page_id,
                        archived=True
                    )
                except Exception as archive_err:
                    # å¦‚æœé¡µé¢å·²ç»è¢«å½’æ¡£ï¼Œå¿½ç•¥é”™è¯¯ç»§ç»­æ‰§è¡Œ
                    if "archived" in str(archive_err).lower():
                        logger.debug(f"Page already archived: {page_id}")
                    else:
                        raise archive_err

                # 2. é‡æ–°åŒæ­¥
                mailbox = store_data.get('mailbox', 'æ”¶ä»¶ç®±')
                full_email = self.arm.fetch_email_by_message_id(message_id, mailbox)

                if not full_email:
                    # é‚®ä»¶åœ¨ Mail.app ä¸­æ‰¾ä¸åˆ°ï¼ˆå¯èƒ½å·²åˆ é™¤æˆ–ç§»åŠ¨ï¼‰
                    # ç›´æ¥åˆ é™¤ SyncStore è®°å½•ï¼Œé¿å…åç»­é‡å¤å¤„ç†
                    self.sync_store.delete_email(message_id)
                    not_found += 1
                    continue

                email_obj = await self._build_email_object(full_email, mailbox)
                if not email_obj:
                    failed += 1
                    self.sync_store.mark_failed(message_id, "Failed to build email object")
                    continue

                new_page_id = await self.notion_sync.create_email_page_v2(
                    email_obj
                )

                if new_page_id:
                    # 3. ç”¨ Mail.app ä¸­çš„æ­£ç¡®æ•°æ®æ›´æ–° SyncStoreï¼ˆä¿®å¤å…ƒæ•°æ®æ±¡æŸ“é—®é¢˜ï¼‰
                    # mark_synced åªæ›´æ–° sync_status å’Œ notion_page_idï¼Œä¸æ›´æ–° subject/sender
                    # æ‰€ä»¥éœ€è¦ç”¨ save_email å®Œæ•´è¦†ç›–
                    self.sync_store.save_email({
                        'message_id': message_id,
                        'subject': email_obj.subject or '',
                        'sender': f"{email_obj.sender_name} <{email_obj.sender}>" if email_obj.sender_name else (email_obj.sender or ''),
                        'date_received': email_obj.date.isoformat() if email_obj.date else '',
                        'thread_id': email_obj.thread_id or '',
                        'mailbox': mailbox,
                        'sync_status': 'synced',
                        'notion_page_id': new_page_id
                    })
                    success += 1
                else:
                    failed += 1
                    self.sync_store.mark_failed(message_id, "Notion create page failed")

            except Exception as e:
                logger.error(f"Failed to fix critical mismatch for {message_id}: {e}")
                failed += 1

        # è¾“å‡ºç»Ÿè®¡
        print(f"\nâœ… å…³é”®ä¿¡æ¯ä¿®å¤å®Œæˆ: æˆåŠŸ {success} å°, å¤±è´¥ {failed} å°", end="")
        if not_found > 0:
            print(f", é‚®ä»¶æ‰¾ä¸åˆ° {not_found} å°")
        else:
            print()

    async def update_all_parent_items(self, auto_confirm: bool = False):
        """éå†æ‰€æœ‰çº¿ç¨‹ï¼Œé‡å»º Parent Item å…³è”ï¼ˆæ–°æ¶æ„ï¼šæœ€æ–°é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹ï¼‰

        æ–°é€»è¾‘ï¼š
        1. å¯¹äºæ¯ä¸ªçº¿ç¨‹ï¼Œæ‰¾åˆ°æœ€æ–°é‚®ä»¶
        2. è®¾ç½®æœ€æ–°é‚®ä»¶çš„ Sub-item åŒ…å«åŒçº¿ç¨‹æ‰€æœ‰å…¶ä»–é‚®ä»¶
        3. è¿™ä¼šè‡ªåŠ¨é‡å»ºæ‰€æœ‰é‚®ä»¶çš„ Parent Item å…³ç³»

        Args:
            auto_confirm: è·³è¿‡ç¡®è®¤æ­¥éª¤
        """
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
        analysis = self.report.parent_analysis
        has_existing_analysis = analysis.get('total', 0) > 0 and 'threads' in analysis

        if not has_existing_analysis:
            # æ‰§è¡Œæ–°çš„åˆ†æ
            print("\nğŸ“Š æ‰§è¡Œ Parent Item åˆ†æï¼ˆæ–°æ¶æ„ï¼‰...")
            await self._analyze_all()
            analysis = self.report.parent_analysis

            if analysis.get('total', 0) == 0:
                print("âŒ åˆ†æå¤±è´¥æˆ–æ²¡æœ‰æ•°æ®")
                return

        # æ˜¾ç¤ºåˆ†æç»“æœ
        summary = analysis.get('summary', {})
        threads = analysis.get('threads', {})

        print(f"\nğŸ“Š Parent Item åˆ†æç»“æœï¼ˆæ–°æ¶æ„ï¼šæœ€æ–°é‚®ä»¶ä¸ºæ¯èŠ‚ç‚¹ï¼‰")
        print(f"  æ€»é‚®ä»¶æ•°: {analysis.get('total', 0)}")
        print(f"  æ€»çº¿ç¨‹æ•°: {summary.get('total_threads', 0)}")
        print(f"    - å•é‚®ä»¶çº¿ç¨‹: {summary.get('single_email_threads', 0)} ä¸ª")
        print(f"    - å¤šé‚®ä»¶çº¿ç¨‹: {summary.get('multi_email_threads', 0)} ä¸ª")
        print(f"  å…³ç³»çŠ¶æ€:")
        print(f"    - å·²æ­£ç¡®: {summary.get('correct', 0)} å°")
        print(f"    - éœ€è¦æ›´æ–°: {summary.get('need_update', 0)} å°")

        # è®¡ç®—éœ€è¦æ“ä½œçš„çº¿ç¨‹æ•°
        threads_need_update = [
            t for t in threads.values()
            if t.get('need_update_latest') or t.get('sub_items_to_set')
        ]

        if not threads_need_update:
            print("\nâœ… æ‰€æœ‰ Parent Item å…³ç³»å·²æ­£ç¡®ï¼Œæ— éœ€æ›´æ–°")
            return

        print(f"\n  éœ€è¦æ›´æ–°çš„çº¿ç¨‹: {len(threads_need_update)} ä¸ª")

        if not auto_confirm:
            confirm = input(f"\nç¡®è®¤æ›´æ–° {len(threads_need_update)} ä¸ªçº¿ç¨‹çš„ Parent Item å…³ç³»? (y/n): ")
            if confirm.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return

        # ç»Ÿè®¡
        stats = {
            'threads_processed': 0,
            'threads_updated': 0,
            'emails_updated': 0,
            'failed': 0
        }

        print(f"\n  å¼€å§‹æ›´æ–° Parent Item å…³ç³»...")

        for i, (thread_id, thread_data) in enumerate(threads.items(), 1):
            if not thread_data.get('need_update_latest') and not thread_data.get('sub_items_to_set'):
                continue

            stats['threads_processed'] += 1
            latest_page_id = thread_data['latest_page_id']
            latest_subject = thread_data.get('latest_subject', '')[:40]
            sub_items = thread_data.get('sub_items_to_set', [])

            # åŒæ—¶åŒ…å«éœ€è¦æ¸…ç©º Parent çš„æœ€æ–°é‚®ä»¶ï¼ˆå¦‚æœæœ‰é”™è¯¯çš„ Parentï¼‰
            # é€šè¿‡è®¾ç½® Sub-item å¯ä»¥ä¸€æ¬¡æ€§å¤„ç†
            all_other_page_ids = [e['page_id'] for e in thread_data.get('other_emails', [])]

            print(f"  [{stats['threads_processed']}/{len(threads_need_update)}] "
                  f"{latest_subject}... ({len(all_other_page_ids)} å°)", end='\r')

            try:
                success = True
                if all_other_page_ids:
                    # è®¾ç½®æœ€æ–°é‚®ä»¶çš„ Sub-itemï¼ˆè¿™ä¼šè‡ªåŠ¨é‡å»º Parent Item å…³ç³»ï¼‰
                    success = await self.notion_sync.update_sub_items(latest_page_id, all_other_page_ids)
                    if success:
                        stats['emails_updated'] += len(all_other_page_ids)
                elif thread_data.get('need_update_latest'):
                    # åªéœ€è¦æ¸…ç©ºæœ€æ–°é‚®ä»¶çš„ Parent Item
                    await self.notion_sync.client.client.pages.update(
                        page_id=latest_page_id,
                        properties={"Parent Item": {"relation": []}}
                    )
                    stats['emails_updated'] += 1

                if success:
                    stats['threads_updated'] += 1
                else:
                    stats['failed'] += 1

            except Exception as e:
                logger.error(f"Failed to update thread {thread_id[:30]}...: {e}")
                stats['failed'] += 1

        # è¾“å‡ºç»Ÿè®¡
        print(f"\n\nâœ… Parent Item å…³ç³»é‡å»ºå®Œæˆ:")
        print(f"   å¤„ç†çº¿ç¨‹: {stats['threads_processed']} ä¸ª")
        print(f"   æˆåŠŸæ›´æ–°: {stats['threads_updated']} ä¸ªçº¿ç¨‹, {stats['emails_updated']} å°é‚®ä»¶")
        print(f"   å¤±è´¥: {stats['failed']} ä¸ª")

    async def sync_new_emails(self, limit: int = None, auto_confirm: bool = False):
        """åŒæ­¥æ–°é‚®ä»¶ï¼ˆä»…åœ¨ SyncStore ä¸­çš„ï¼‰"""
        items = self.comparison.get('store_only', [])
        if not items:
            print("âœ… æ²¡æœ‰éœ€è¦åŒæ­¥çš„æ–°é‚®ä»¶")
            return

        if limit:
            items = items[:limit]

        print(f"\n åŒæ­¥æ–°é‚®ä»¶: {len(items)} å°")

        if not auto_confirm:
            confirm = input(f"ç¡®è®¤åŒæ­¥ {len(items)} å°æ–°é‚®ä»¶? (y/n): ")
            if confirm.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return

        # ç›´æ¥åŒæ­¥æŒ‡å®šçš„ message_idsï¼Œè€Œä¸æ˜¯ä» get_pending_emails è·å–
        success, failed, not_found = await self._sync_specific_emails(items)
        print(f"\nâœ… æ–°é‚®ä»¶åŒæ­¥å®Œæˆ: æˆåŠŸ {success} å°, å¤±è´¥ {failed} å°", end="")
        if not_found > 0:
            print(f", é‚®ä»¶æ‰¾ä¸åˆ° {not_found} å°ï¼ˆå·²åˆ é™¤è®°å½•ï¼‰")
        else:
            print()


async def main():
    parser = argparse.ArgumentParser(description="MailAgent åˆå§‹åŒ–åŒæ­¥")
    parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤æ­¥éª¤")
    parser.add_argument("--limit", "-l", type=int, help="é™åˆ¶åŒæ­¥æ•°é‡")
    parser.add_argument("--action", "-a", type=str, choices=[
        "analyze",           # ä»…åˆ†æå¯¹æ¯”ï¼ˆåŒ…å« Parent Item åˆ†æï¼‰
        "fetch-cache",       # ä»…è·å–é‚®ä»¶åˆ°ç¼“å­˜ï¼ˆé¢„çƒ­ï¼‰
        "fix-properties",    # ä¿®å¤ date/thread_id ä¸åŒ
        "fix-critical",      # é‡æ–°åŒæ­¥å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶
        "update-all-parents", # éå†éªŒè¯å¹¶ä¿®å¤æ‰€æœ‰ Parent Itemï¼ˆåŒ…å«çº¿ç¨‹å¤´åŒæ­¥ï¼‰
        "sync-new",          # åŒæ­¥æ–°é‚®ä»¶
        "all"                # æ‰§è¡Œæ‰€æœ‰ä¿®å¤å’ŒåŒæ­¥
    ], help="æ‰§è¡ŒæŒ‡å®šæ“ä½œ")
    parser.add_argument("--output", "-o", type=str, help="ä¿å­˜åˆ†ææŠ¥å‘Šåˆ° JSON æ–‡ä»¶")
    parser.add_argument("--input", "-i", type=str, help="ä» JSON æ–‡ä»¶åŠ è½½åˆ†ææŠ¥å‘Š")
    parser.add_argument("--skip-fetch", action="store_true", help="è·³è¿‡ä» Mail.app è·å–é‚®ä»¶ï¼ˆä»…å¯¹æ¯”ç°æœ‰æ•°æ®ï¼‰")
    parser.add_argument("--inbox-count", type=int, default=0, help="æ”¶ä»¶ç®±è·å–æ•°é‡é™åˆ¶ (0=ä¸é™åˆ¶)")
    parser.add_argument("--sent-count", type=int, default=0, help="å‘ä»¶ç®±è·å–æ•°é‡é™åˆ¶ (0=ä¸é™åˆ¶)")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(sys.stderr, level="WARNING")

    # æ„å»ºé‚®ç®±æ•°é‡é™åˆ¶
    mailbox_limits = {}
    if args.inbox_count > 0:
        mailbox_limits["æ”¶ä»¶ç®±"] = args.inbox_count
    if args.sent_count > 0:
        mailbox_limits["å‘ä»¶ç®±"] = args.sent_count

    sync = InitialSync(mailbox_limits=mailbox_limits)

    # å¦‚æœæŒ‡å®šäº†è¾“å…¥æ–‡ä»¶ï¼ŒåŠ è½½æŠ¥å‘Š
    if args.input:
        try:
            sync.report = AnalysisReport.load(args.input)
        except Exception as e:
            print(f"âŒ åŠ è½½æŠ¥å‘Šå¤±è´¥: {e}")
            return

    if args.action == "analyze":
        # ä»…åˆ†æï¼Œä¸åŒæ­¥
        # å¦‚æœæ²¡æœ‰æŒ‡å®š count é™åˆ¶ï¼Œé»˜è®¤è·³è¿‡è·å–ï¼ˆé¿å…æ— é™è·å–ï¼‰
        skip_fetch = args.skip_fetch
        if not mailbox_limits and not skip_fetch:
            print("æç¤º: æœªæŒ‡å®š --inbox-count/--sent-countï¼Œé»˜è®¤è·³è¿‡è·å–é‚®ä»¶")
            print("      å¦‚éœ€è·å–æ–°é‚®ä»¶ï¼Œè¯·æŒ‡å®šæ•°é‡æˆ–ä½¿ç”¨ --action fetch-cache")
            skip_fetch = True

        await sync.analyze_only(skip_fetch=skip_fetch)

        # ä¿å­˜æŠ¥å‘Š
        if args.output:
            sync.report.save(args.output)

        print("\n åˆ†æå®Œæˆï¼å¯ç”¨çš„ä¿®å¤æ“ä½œ:")
        print("   --action fix-properties      ä¿®å¤ date/thread_id ä¸åŒ")
        print("   --action fix-critical        é‡æ–°åŒæ­¥å…³é”®ä¿¡æ¯ä¸åŒçš„é‚®ä»¶")
        print("   --action update-all-parents  éå†éªŒè¯å¹¶ä¿®å¤æ‰€æœ‰ Parent Itemï¼ˆåŒ…å«çº¿ç¨‹å¤´åŒæ­¥ï¼‰")
        print("   --action sync-new            åŒæ­¥æ–°é‚®ä»¶")
        print("   --action all                 æ‰§è¡Œæ‰€æœ‰æ“ä½œ")
        print("\n æç¤º: ä½¿ç”¨ --output ä¿å­˜æŠ¥å‘Šï¼Œåç»­ç”¨ --input åŠ è½½å¿«é€Ÿæ‰§è¡Œ")

    elif args.action == "fetch-cache":
        # ä»…é¢„çƒ­ç¼“å­˜ï¼Œä¸åš Notion å¯¹æ¯”å’ŒåŒæ­¥
        print("=" * 60)
        print("SyncStore ç¼“å­˜é¢„çƒ­")
        print("=" * 60)
        if mailbox_limits:
            print(f"\nç›®æ ‡æ•°é‡:")
            for mb, count in mailbox_limits.items():
                print(f"  - {mb}: {count} å°")
        else:
            print("\næœªæŒ‡å®šæ•°é‡é™åˆ¶ï¼Œå°†è·å–æ‰€æœ‰é‚®ä»¶")
            print("æç¤º: ä½¿ç”¨ --inbox-count å’Œ --sent-count æŒ‡å®šæ•°é‡")

        await sync._fetch_emails_from_applescript()

        # è®°å½•å½“å‰ max_row_idï¼ˆç”¨äºåç»­å¢é‡åŒæ­¥ï¼‰
        sync._record_current_max_row_id()

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        stats = sync.sync_store.get_stats()
        print("\n" + "=" * 60)
        print("ç¼“å­˜é¢„çƒ­å®Œæˆ")
        print("=" * 60)
        print(f"\nSyncStore çŠ¶æ€:")
        print(f"  - æ€»é‚®ä»¶æ•°: {stats.get('total_emails', 0)}")
        by_mailbox = stats.get('by_mailbox', {})
        for mb, count in by_mailbox.items():
            print(f"    - {mb}: {count} å°")
        print(f"  - pending: {stats.get('pending', 0)}")
        print(f"  - synced: {stats.get('synced', 0)}")
        print(f"  - last_max_row_id: {stats.get('last_max_row_id', 'N/A')}")

    elif args.action:
        # å¦‚æœæ²¡æœ‰åŠ è½½æŠ¥å‘Šï¼Œå…ˆè¿è¡Œåˆ†æ
        if not args.input:
            # å¦‚æœæ²¡æœ‰æŒ‡å®š count é™åˆ¶ï¼Œé»˜è®¤è·³è¿‡è·å–ï¼ˆé¿å…æ— é™è·å–ï¼‰
            skip_fetch = args.skip_fetch
            if not mailbox_limits and not skip_fetch:
                print("æç¤º: æœªæŒ‡å®š --inbox-count/--sent-countï¼Œé»˜è®¤è·³è¿‡è·å–é‚®ä»¶")
                skip_fetch = True
            await sync.analyze_only(skip_fetch=skip_fetch)

        # æ ¹æ® action æ‰§è¡Œå¯¹åº”æ“ä½œ
        if args.action == "fix-properties":
            await sync.fix_properties(auto_confirm=args.yes)
        elif args.action == "fix-critical":
            await sync.fix_critical_mismatch(auto_confirm=args.yes)
        elif args.action == "update-all-parents":
            await sync.update_all_parent_items(auto_confirm=args.yes)
        elif args.action == "sync-new":
            await sync.sync_new_emails(limit=args.limit, auto_confirm=args.yes)
        elif args.action == "all":
            print("\n" + "=" * 50)
            print("æ‰§è¡Œæ‰€æœ‰ä¿®å¤å’ŒåŒæ­¥æ“ä½œ")
            print("=" * 50)

            await sync.fix_properties(auto_confirm=args.yes)
            await sync.fix_critical_mismatch(auto_confirm=args.yes)
            await sync.sync_new_emails(limit=args.limit, auto_confirm=args.yes)
            await sync.update_all_parent_items(auto_confirm=args.yes)  # ç»Ÿä¸€æ›´æ–° Parent Itemï¼ˆåŒ…å«çº¿ç¨‹å¤´åŒæ­¥ï¼‰

            print("\nâœ… æ‰€æœ‰æ“ä½œå®Œæˆï¼")
    else:
        # é»˜è®¤ï¼šè¿è¡Œå®Œæ•´æµç¨‹
        await sync.run(auto_confirm=args.yes, limit=args.limit)

    # å…³é—­ aiohttp sessionï¼Œé¿å… "Unclosed client session" è­¦å‘Š
    await sync.notion_sync.client.close()


if __name__ == "__main__":
    asyncio.run(main())
